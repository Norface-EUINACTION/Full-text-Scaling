# -*- coding: utf-8 -*-
"""lcs_trilog_candidates_prop_final_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Q15nt36Ug2KgMqDCd1-13JSb_BvyVrN
"""

import pandas as pd
import os
import re
from statistics import median, mean
import nltk
import glob
import os
import copy
nltk.download('punkt')
from nltk.tokenize import word_tokenize
regex = "[^a-zA-Z :\.]"
html = re.compile(r'<[^>]+>')
from collections import Counter
from itertools import groupby
from operator import itemgetter
import nltk
nltk.download('wordnet')
import traceback

def get_cod_name(s):
  x = os.path.splitext(s)[0]
  x = x.split('/')
  x = x[-1].split('_')

  return ''.join([x[-1]])

# clean text
def pre_process(coms, eps, council):
  #lower case
  coms = [x.lower() for x in coms]
  eps = [x.lower() for x in eps]
  council = [x.lower() for x in council]


  c = list()
  e = list()
  d = list()
  for i, j, k  in zip(coms, eps, council):
     i = re.sub("\s\s+" , " ", i)
     i = re.sub(html, " ", i)
     i = re.sub(regex, " ", i)
     j = re.sub(html , " ", j)
     j = re.sub(regex, " ", j)
     k = re.sub(html, " ", k)
     k = re.sub(regex, " ", k)

     #strip of leading and trailing space and multiple spaces
     i = i.strip()
     i = re.sub(r'\s+', ' ', i)
     j = j.strip()
     j = re.sub(r'\s+', ' ', j)
     k = k.strip()
     k = re.sub(r'\s+', ' ', k)

     c.append(i)
     e.append(j)
     d.append(k)

  return c, e, d

#edge case measure
def remove_whitespace_token(word_list):
  temp = list()

  # remove whitespace
  for s in word_list:
    temp.append(s.strip())

  return temp

def LCS(X, Y):
    # X is the text from trilog
    # Y is the full text
    X = remove_whitespace_token(X)
    Y = remove_whitespace_token(Y)

    m = len(X)
    n = len(Y)
    L = [[0 for i in range(n+1)] for j in range(m+1)]

    # Build L[m+1][n+1] in bottom up fashion. Note
    # that L[i][j] contains length of LCS of X[0..i-1] and Y[0..j-1]
    for i in range(m+1):
        for j in range(n+1):
            if i == 0 or j == 0:
                L[i][j] = 0
            elif X[i-1] == Y[j-1]:
                L[i][j] = L[i-1][j-1] + 1
            else:
                L[i][j] = max(L[i-1][j], L[i][j-1])

        # Create a string variable to store the lcs string
    lcs = list()
    indexes = list()
    # Start from the bottom right corner and
    # one by one store characters in lcs[]
    i = m
    j = n
    while i > 0 and j > 0:

        # If current word in X[] and Y[] are same, then
        # current word is part of LCS
        if X[i-1] == Y[j-1]:
            lcs.append(Y[j-1])
            indexes.append(j-1)
            i -= 1
            j -= 1

        # If not same, then find the larger of two and
        # move in the direction of larger value
        elif L[i-1][j] > L[i][j-1]:
            i -= 1

        else:
            j -= 1

    # LCS is the reverse of what we got
    lcs = lcs[::-1]

    return (lcs, indexes[::-1])

#return continious sequence of indicies
def candidate_indices(indices_list):
  _candidates = list()

  # k is the key for each group g
  for k, g in groupby(enumerate(indices_list), lambda i_x: i_x[0] - i_x[1]):
    _candidates.append(list(map(itemgetter(1), g)))

  new_list=[x for x in _candidates if len(x)>=10]

  return new_list

def find_longest_sublist(sublists, mode=None):
    longest_sublist = max(sublists, key=len)
    return longest_sublist

def convert_index_to_string(index_list, text):
  if index_list == 'empty':
    return 'empty'
  else:
    return ' '.join(text[index_list[0]:index_list[-1]])


def compute_difference(l, l1):

  #l is the list of lists of matching indicies
  #l1 is the list of indicies of the full text
  flattened_sub_lists = [item for sublist in l for item in sublist]

  l1 = [idx for idx , i in enumerate(l1)]

  # Find the elements in l1 that are not in the flattened_sub_lists
  answer = [x for x in l1 if x not in flattened_sub_lists] 

    # Group the result
  grouped = []
  temp = [answer[0]]

  for i in range(1, len(answer)):
      if answer[i] - answer[i-1] <= 10:
          temp.append(answer[i])
      else:
          grouped.append(temp)
          temp = [answer[i]]

  # Append any remaining numbers to the result
  if temp:
      grouped.append(temp)

  return grouped

def convert_lists_to_tups_proposal(a,b,c,text):
  final_results = list()
  
  matching_indicies = list()

  for c, e, n, in zip(a, b, c):
    com = convert_index_to_string(c, text)
    ep = convert_index_to_string(e, text)
    cn = convert_index_to_string(c, text)

    longest = find_longest_sublist([com,ep,cn])
    if longest == 'empty':
      final_results.append((com,ep,cn,'',''))

    elif longest == com and longest == ep and longest == cn:
      final_results.append((com,ep,cn,com,'best match from Council'))
      matching_indicies.append(n)
    elif longest == com and longest == cn:
      final_results.append((com,ep,cn,com,'best match from Council'))
      matching_indicies.append(n)
    elif longest == com and longest == ep:
      final_results.append((com,ep,cn,com,'best match from EP'))
      matching_indicies.append(e)
    elif longest == com:
      final_results.append((com,ep,cn,com,'best match from COM'))
      matching_indicies.append(c)

    elif longest == ep:
      final_results.append((com,ep,cn,ep,'best match from EP'))
      matching_indicies.append(e)

    elif longest == cn:
      final_results.append((com,ep,cn,ep,'best match from Council'))
      matching_indicies.append(n)


  final_difference_indicies = compute_difference(matching_indicies,text)
  final_difference_indicies = [i for i in final_difference_indicies if len(i) > 4]


  final_difference = list()
  for i in final_difference_indicies:
    final_difference.append(text[i[0]:i[-1]])


  return final_results,final_difference

def convert_lists_to_tups_final(a,b,c,d,text):
  final_results = list()
  matching_indicies = list()
  for c, e, n, p in zip(a, b, c, d):
    com = convert_index_to_string(c, text)
    ep = convert_index_to_string(e, text)
    cn = convert_index_to_string(n, text)
    prop = convert_index_to_string(p, text)

    longest = find_longest_sublist([com,ep,cn])

    if longest == 'empty':
      final_results.append((com,ep,cn,'',''))

    elif longest == com and longest == cn and longest == ep:
      final_results.append((com,ep,cn,prop, cn,'best match from Council'))
      matching_indicies.append(n)

    elif longest == com and longest == cn:
      final_results.append((com,ep,cn,prop, cn,'best match from Council'))
      matching_indicies.append(n)
    elif longest == com and longest == ep:
      final_results.append((com,ep,cn,prop, ep,'best match from EP'))
      matching_indicies.append(e)
    elif longest == com:
      final_results.append((com,ep,cn,prop, com,'best match from COM'))
      matching_indicies.append(c)
    elif longest == ep:
      final_results.append((com,ep,cn, prop, ep,'best match from EP'))
      matching_indicies.append(e)
    elif longest == cn:
      final_results.append((com,ep,cn, prop, cn,'best match from Council'))
      matching_indicies.append(c)
    elif longest == prop:
      final_results.append((com,ep,cn, prop, prop, 'best match from Proposal'))
      matching_indicies.append(p)


  final_difference_indicies = compute_difference(matching_indicies,text)
  final_difference_indicies = [i for i in final_difference_indicies if len(i) > 4]


  final_difference = list()
  for i in final_difference_indicies:
    final_difference.append(text[i[0]:i[-1]])



  return final_results, final_difference

def run_alignment_prop(COMS,EPS,COUNCIL,full_text):
  results_candidates_all_com = list() # commision, eps, council, matching_com, matching_eps, matching_council,full_final, Com_eps_council
  results_candidates_all_ep = list()
  results_candidates_all_cn = list()
  final_text_tokens = word_tokenize(full_text)

  for i, j, k in zip(COMS, EPS, COUNCIL):
    tokens_coms = word_tokenize(i)
    tokens_ep = word_tokenize(j)
    tokens_cn = word_tokenize(k)

    #print(tokens_ep)
    match_com_text, match_com_indices = LCS(tokens_coms, final_text_tokens)
    match_ep_text, match_ep_indices= LCS(tokens_ep, final_text_tokens)
    match_cn_text, match_cn_indices = LCS(tokens_cn, final_text_tokens)

    candidates_com = candidate_indices(match_com_indices)
    #print(candidates_com)
    if len(candidates_com) == 0:
      results_candidates_all_com.append('empty')
    else:
      candidates_com = find_longest_sublist(candidates_com)
      results_candidates_all_com.append(candidates_com)

    candidates_ep = candidate_indices(match_ep_indices)
    #print(candidates_ep)
    if len(candidates_ep) == 0:
      results_candidates_all_ep.append('empty')
    else:
      candidates_ep = find_longest_sublist(candidates_ep)
      results_candidates_all_ep.append(candidates_ep)

    #print(candidates_ep)
    candidates_cn = candidate_indices(match_cn_indices)
    if len(candidates_cn) == 0:
      results_candidates_all_cn.append('empty')
    else:
      candidates_cn = find_longest_sublist(candidates_cn)
      results_candidates_all_cn.append(candidates_cn)




  final,difference =  convert_lists_to_tups_proposal(results_candidates_all_com,
                                results_candidates_all_ep,
                                results_candidates_all_cn,
                                final_text_tokens)
  
  difference = [' '.join(i) for i in difference]

  return final, difference

def run_alignment_final(COMS,EPS,COUNCIL,PROP,full_text):
  results_candidates_all_com = list() # commision, eps, council, matching_com, matching_eps, matching_council,full_final, Com_eps_council
  results_candidates_all_ep = list()
  results_candidates_all_cn = list()
  results_candidates_all_prop = list()

  final_text_tokens = word_tokenize(full_text)
  #count = 0
  #result_final = list()
  #PROPOSAL = list(prop_df['text_in_full_proposal'])

  for i, j, k, p in zip(COMS, EPS, COUNCIL, PROP):
    tokens_coms = word_tokenize(i)
    tokens_ep = word_tokenize(j)
    tokens_cn = word_tokenize(k)
    tokens_prop = word_tokenize(p)

    #print(tokens_ep)
    match_com_text, match_com_indices = LCS(tokens_coms, final_text_tokens)
    match_ep_text, match_ep_indices= LCS(tokens_ep, final_text_tokens)
    match_cn_text, match_cn_indices = LCS(tokens_cn, final_text_tokens)
    match_prop_text, match_prop_indices = LCS(tokens_prop, final_text_tokens)

    candidates_com = candidate_indices(match_com_indices)
    #print(candidates_com)
    if len(candidates_com) == 0:
      results_candidates_all_com.append('empty')
    else:
      candidates_com = find_longest_sublist(candidates_com)
      results_candidates_all_com.append(candidates_com)

    candidates_ep = candidate_indices(match_ep_indices)
    #print(candidates_ep)
    if len(candidates_ep) == 0:
      results_candidates_all_ep.append('empty')
    else:
      candidates_ep = find_longest_sublist(candidates_ep)
      results_candidates_all_ep.append(candidates_ep)

    #print(candidates_ep)
    candidates_cn = candidate_indices(match_cn_indices)
    if len(candidates_cn) == 0:
      results_candidates_all_cn.append('empty')
    else:
      candidates_cn = find_longest_sublist(candidates_cn)
      results_candidates_all_cn.append(candidates_cn)

    #print(candidates_prop)
    candidates_prop = candidate_indices(match_prop_indices)
    if len(candidates_prop) == 0:
      results_candidates_all_prop.append('empty')

    else:
      candidates_prop = find_longest_sublist(candidates_prop)
      results_candidates_all_prop.append(candidates_prop)


  final, difference =  convert_lists_to_tups_final(results_candidates_all_com,
                                results_candidates_all_ep,
                                results_candidates_all_cn,
                                results_candidates_all_prop,
                                final_text_tokens)
  
  difference = [' '.join(i) for i in difference]

  return final, difference

# takes in two strings s1 and s2, returns sequences of words from s2 that
# do not appear in s1 or do not follow the same order as they do in s1

"""# Proposal"""

trilog_base_path = '/ceph/sobaidul/data/Full_sample_parsed_trilogues'
proposal_alignment_path = '/ceph/sobaidul/data/aligned_proposals'
filenames = glob.glob(f'{trilog_base_path}/*.csv')
df_prop_full = pd.read_csv('/ceph/sobaidul/data/full_proposal.csv', sep=',')
count=0
logf = open(f"/ceph/sobaidul/data/error_prop.log", "w")

for f in filenames:
  try:
      print(count)
      cod_name = get_cod_name(f)
      df_tri = pd.read_csv(f, sep = ',')
      df_tri = df_tri.fillna('')
      print('Length of trilog: ' + str(len(df_tri.index)) + '\n')
      p_text = df_prop_full.loc[df_prop_full['year-cod'] == cod_name, 'text'].iloc[0]
      p_text = re.sub(regex, ' ', p_text)
      p_text = p_text.lower()
      COM = list(df_tri['COM'])
      EP= list(df_tri['EP'])
      CNC = list(df_tri['Council'])
      COM, EP, CNC= pre_process(COM, EP, CNC)

      result_final, diff_text = run_alignment_prop(COM,EP,CNC,p_text)
      temp_df = pd.DataFrame(result_final,columns=['COM_match', 'EP_match', 'Council_match','Longest_match_prop','match_from_for_prop'])
      new_data_df = pd.DataFrame(diff_text, columns=['Longest_match_prop'])


      df_with_diff = temp_df.append(new_data_df, ignore_index=True)

      df_merged = pd.concat([df_tri,df_with_diff], axis=1)

      name = f.split('/')[-1]
      df_merged.to_csv(f'{proposal_alignment_path}/alignment_prop_{name}', sep=',' ,index=False)

      count+=1

      print(f'Finished ' + str(count) + f'. File: {name}')

  except Exception as e:
      print("Exception: " + str(e))
      print("For file: " + str(f))
      print(traceback.format_exc())
      logf.write("Failed to open and run {0}: {1}\n".format(str(f), str(e)))

"""# Final"""

print('Running for Final Text\n')
trilog_base_path = '/ceph/sobaidul/data/aligned_proposals'
alignment_path = '/ceph/sobaidul/data/aligned_finals'
filenames = glob.glob(f'{trilog_base_path}/*.csv')
df_final_full = pd.read_csv('/ceph/sobaidul/data/final_act_full.csv', sep=',')
df_final_full = df_final_full.groupby(['cod'])['text'].apply(' '.join).reset_index()
count=0
logf = open(f"/ceph/sobaidul/data/error_final.log", "w")
for f in filenames:
  try:
    cod_name = get_cod_name(f)
    df_tri = pd.read_csv(f, sep = ',')
    df_tri = df_tri.fillna('')

    f_text = df_final_full.loc[df_final_full['cod'] == cod_name, 'text'].iloc[0]
    f_text = re.sub(regex, ' ', f_text)
    f_text = f_text.lower()
    COM = list(df_tri['COM'])
    EP= list(df_tri['EP'])
    CNC = list(df_tri['Council'])
    PRO = list(df_tri['Longest_match_prop'])
    COM, EP, CNC= pre_process(COM, EP, CNC)

    print(count)
    print('Length of trilog: ' + str(len(df_tri.index)) + '\n')
    result_final, diff_text = run_alignment_final(COM,EP,CNC,PRO,f_text)
    temp_df = pd.DataFrame(result_final,columns=['COM_match', 'EP_match', 'Council_match','Proposal_match', 'Longest_match_final','match_from_for_final'])
    new_data_df = pd.DataFrame(diff_text, columns=['Longest_match_final'])
    df_with_diff = temp_df.append(new_data_df, ignore_index=True)

    df_merged = pd.concat([df_tri,df_with_diff], axis=1)

    name = f.split('/')[-1]
    name = name.replace('alignment_prop_','')
    df_merged.to_csv(f'{alignment_path}/alignment_final_{name}', sep=',' ,index=False)

    print(f'Finished ' + str(count) + f'. File: {name}')

    count += 1

  except Exception as e:
    print("Exception: " + str(e))
    print("For file: " + str(f))
    print(traceback.format_exc())
    logf.write("Failed to open and run {0}: {1}\n".format(str(f), str(e)))
